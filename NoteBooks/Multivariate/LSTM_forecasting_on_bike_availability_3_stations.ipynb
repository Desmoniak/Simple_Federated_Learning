{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/benhamner/sf-bay-area-bike-share?select=status.csv\n",
    "dataset_station_statut = pd.read_csv(\"../../Bike_Data/status.csv\")\n",
    "dataset_station = pd.read_csv(\"../../Bike_Data/station.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a PyTorch dataset to generate input/target pairs for the LSTM model\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, window_size, stride):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.data[idx:idx+self.window_size]\n",
    "        target = self.data[idx+self.window_size]\n",
    "        return inputs, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class LSTM v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your LSTM model here with num_layers LSTM layers and 1 fully connected layer\n",
    "class LSTMModel_v1(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station statut dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_station.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataset Station statut and Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.merge(dataset_station, dataset_station_statut, left_on='id', right_on='station_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ (Mulivariate) Selection three station to make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All id station available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['id'].unique())\n",
    "print(len(dataset['id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id = dataset.loc[dataset['id'].isin([42, 70, 60])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_count = dataset_station_id['dock_count'].unique()\n",
    "print(dock_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id_transform = dataset_station_id.drop([\"name\", 'lat', 'long', 'id', 'city', 'installation_date', \"docks_available\", \"dock_count\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id_transform.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check presence of null and NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id_transform.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id_transform[dataset_station_id_transform.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id_transform.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion column time to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id_transform['time'] = pd.to_datetime(dataset_station_id_transform['time'], format=\"mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_station_id_transform.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id_transform.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_station_id_transform.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_valid(valid_losses):\n",
    "    plt.plot(valid_losses, label = 'Val Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model and evaluate on the validation set\n",
    "def train_model(model, optimizer, criterion, train_loader, valid_loader, num_epochs):\n",
    "    num_epochs = num_epochs\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, targets.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_losses.append(loss.item())\n",
    "        val_loss = 0.0\n",
    "    \n",
    "        for inputs, targets in valid_loader:\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, targets.float())\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(valid_loader)\n",
    "        valid_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model_LSTM.pth')\n",
    "    \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "    plot_loss_valid(valid_losses)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(best_model, test_loader, criterion):\n",
    "    # Load the best model and evaluate on the test set\n",
    "    best_model.double()\n",
    "    best_model.eval()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss = 0.0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            x = torch.Tensor(inputs).unsqueeze(1).to(device)\n",
    "            y = torch.Tensor(targets).unsqueeze(0).to(device)\n",
    "            outputs = best_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            # Save the predictions and actual values for plotting later\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "            actuals.append(targets.cpu().numpy())\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    # Concatenate the predictions and actuals\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    return (predictions, actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Metrics for each month Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "def result_prediction_by_month(predictions, actuals):\n",
    "    indices_by_month = []\n",
    "    EPSILON = 1e-10\n",
    "    for i in range(1): \n",
    "        grouped_data = test_data.groupby(pd.Grouper(freq='M'))\n",
    "        for name , group in grouped_data:\n",
    "            indices = np.where(test_data.index.isin(group.index))[0]\n",
    "            indices_by_month.append((name.strftime('%B'), indices))\n",
    "            \n",
    "        for name, indice in indices_by_month :\n",
    "            y_pred = predictions[indice-window_size,i]\n",
    "            y_true = actuals[indice-window_size,i]\n",
    "            \n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            maape =  np.mean(np.arctan(np.abs((y_true - y_pred) / (y_true + EPSILON))))\n",
    "            # Add evaluation metrics to the plot\n",
    "            print(f'\\n{name}')\n",
    "            print(f'MAE: {mae:.2f}')\n",
    "            print(f'MAPE: {mape:.2f}')\n",
    "            print(f'RMSE: {rmse:.2f}')\n",
    "            print(f'MAAPE: {maape:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Plot to see accuracy and some Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "def plot_result_prediction(predictions, actuals):\n",
    "    EPSILON = 1e-10\n",
    "    for i in range(3): \n",
    "        for y in range(0, len(test_data), 8):\n",
    "            plt.figure(figsize=(28, 5))\n",
    "            plt.rcParams.update({'font.size': 16})  # Augmenter la taille de la police\n",
    "            plt.gcf().set_size_inches(20, 8)  # Augmenter la taille de la figure\n",
    "\n",
    "            debut = y\n",
    "            fin = min(y + 8, len(test_data))\n",
    "                \n",
    "            plt.title('Actual vs Prediction of station N° {}'.format(pivoted_df_station_id.columns[i]))\n",
    "            y_pred = predictions[debut:fin,i]\n",
    "            y_true = actuals[debut:fin,i]\n",
    "            plt.plot(test_data.index[debut + window_size: fin + window_size],predictions[debut:fin, i], label='Actuals')\n",
    "            plt.plot(test_data.index[debut + window_size: fin + window_size],actuals[debut:fin, i], label='Predictions')\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            maape =  np.mean(np.arctan(np.abs((y_true - y_pred) / (y_true + EPSILON))))\n",
    "            # Add evaluation metrics to the plot\n",
    "            plt.annotate(f'MAE: {mae:.2f}', xy=(0.005, 0.85), xycoords='axes fraction')\n",
    "            plt.annotate(f'MAPE: {mape:.2f}', xy=(0.005, 0.80), xycoords='axes fraction')\n",
    "            plt.annotate(f'RMSE: {rmse:.2f}', xy=(0.005, 0.75), xycoords='axes fraction')\n",
    "            plt.annotate(f'MAAPE: {maape:.2f}', xy=(0.005, 0.70), xycoords='axes fraction')\n",
    "\n",
    "            # Set x and y labels\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Value')\n",
    "            plt.legend()\n",
    "            print(mae,mape,rmse,maape)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Experimentation group by day and hour "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to forecast the availability of bikes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df_station_id = dataset_station_id_transform.pivot_table(index='time', columns='station_id', values='bikes_available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekday_hour = pivoted_df_station_id.groupby(pd.Grouper(freq='H'), dropna=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_weekday_hour[df_weekday_hour.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekday_hour = df_weekday_hour.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_weekday_hour[df_weekday_hour.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekday_hour_prep = df_weekday_hour.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekday_hour_prep.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekday_hour_prep[df_weekday_hour_prep.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_weekday_hour_prep[:'2014-10-31 12:00:00']\n",
    "valid_data = df_weekday_hour_prep['2014-10-31 12:00:00':'2015-02-01 12:00:00']\n",
    "test_data = df_weekday_hour_prep['2015-02-01 12:00:00':'2015-08-31 12:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sliding window size and stride\n",
    "window_size = 7\n",
    "stride = 1\n",
    "layers = 3\n",
    "hidden_size = 32\n",
    "input = 3\n",
    "output = 3\n",
    "# Create datasets and data loaders for training, validation, and test sets\n",
    "train_dataset = TimeSeriesDataset(train_data.values, window_size, stride)\n",
    "valid_dataset = TimeSeriesDataset(valid_data.values, window_size, stride)\n",
    "test_dataset = TimeSeriesDataset(test_data.values, window_size, stride)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your LSTM model and define the loss function and optimizer\n",
    "model = LSTMModel_v1(input_size=input, hidden_size=hidden_size, num_layers=layers, output_size=output)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, optimizer, criterion, train_loader, valid_loader, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model =  LSTMModel_v1(input_size=input, hidden_size=32, num_layers=layers, output_size=output)\n",
    "best_model.load_state_dict(torch.load('best_model_LSTM.pth'.format(input)))\n",
    "predictions, actuals = test_model(best_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prediction_by_month(predictions, actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result_prediction(predictions, actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Experimentation group by day and 10 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ten_minutes = dataset_station_id_transform.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ten_minutes = df_ten_minutes.groupby(by=pd.Grouper(key='time', freq='10min'), dropna=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ten_minutes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ten_minutes[df_ten_minutes.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ten_minutes = df_ten_minutes.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ten_minutes[df_ten_minutes.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ten_minutes_prep = df_ten_minutes.drop(['dock_count', \"docks_available\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_ten_minutes_prep[:'2014-10-31 12:00:00']\n",
    "val_data = df_ten_minutes_prep['2014-10-31 12:00:00':'2015-02-01 12:00:00']\n",
    "test_data = df_ten_minutes_prep['2015-02-01 12:00:00':'2015-08-31 12:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sliding window size and stride\n",
    "window_size = 7\n",
    "stride = 1\n",
    "layers = 3\n",
    "hidden_size = 32\n",
    "n = 1\n",
    "# Create datasets and data loaders for training, validation, and test sets\n",
    "train_dataset = TimeSeriesDataset(train_data.values, window_size, stride)\n",
    "val_dataset = TimeSeriesDataset(val_data.values, window_size, stride)\n",
    "test_dataset = TimeSeriesDataset(test_data.values, window_size, stride)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your LSTM model and define the loss function and optimizer\n",
    "model = LSTMModel_v1(input_size=n, hidden_size=hidden_size, num_layers=layers, output_size=n)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, optimizer, criterion, train_loader, valid_loader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LSTMModel_v1(input_size=n, hidden_size=32, num_layers=layers, output_size=n)\n",
    "best_model.load_state_dict(torch.load('best_model_LSTM.pth'.format(n)))\n",
    "predictions, actuals = test_model(best_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prediction_by_month(predictions, actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result_prediction(predictions, actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Experimentation group by day and 30 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thirty_minutes = dataset_station_id_transform.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thirty_minutes = df_thirty_minutes.groupby(by=pd.Grouper(key='time', freq='30min'), dropna=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thirty_minutes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ten_minutes[df_ten_minutes.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thirty_minutes = df_thirty_minutes.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thirty_minutes_prep = df_ten_minutes.drop(['dock_count', \"docks_available\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df_thirty_minutes_prep[:'2014-10-31 12:00:00']\n",
    "val_data = df_thirty_minutes_prep['2014-10-31 12:00:00':'2015-02-01 12:00:00']\n",
    "test_data = df_thirty_minutes_prep['2015-02-01 12:00:00':'2015-08-31 12:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sliding window size and stride\n",
    "window_size = 7\n",
    "stride = 1\n",
    "layers = 3\n",
    "hidden_size = 32\n",
    "n = 1\n",
    "# Create datasets and data loaders for training, validation, and test sets\n",
    "train_dataset = TimeSeriesDataset(train_data.values, window_size, stride)\n",
    "val_dataset = TimeSeriesDataset(val_data.values, window_size, stride)\n",
    "test_dataset = TimeSeriesDataset(test_data.values, window_size, stride)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your LSTM model and define the loss function and optimizer\n",
    "model = LSTMModel_v1(input_size=n, hidden_size=hidden_size, num_layers=layers, output_size=n)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, optimizer, criterion, train_loader, valid_loader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LSTMModel_v1(input_size=n, hidden_size=32, num_layers=layers, output_size=n)\n",
    "best_model.load_state_dict(torch.load('best_model_LSTM.pth'.format(n)))\n",
    "predictions, actuals = test_model(best_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_prediction_by_month(predictions, actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result_prediction(predictions, actuals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
